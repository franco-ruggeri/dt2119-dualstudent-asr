{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dualstudent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-97HlNQ9uRFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "071e7d21-7762-49b4-9140-148ffc51d1e7"
      },
      "source": [
        "#@title Mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv1Vkh0iIGaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "33c3e8e3-c792-4af7-b3b7-e14ce9367973"
      },
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "!pip install python_speech_features"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-speech-features: filename=python_speech_features-0.6-cp36-none-any.whl size=5887 sha256=7577a4508fc37fae8ae5b5152cee501fff3b15f084c5d821679a77a8ece9b732\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: python-speech-features\n",
            "Successfully installed python-speech-features-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ESFs8JXvHBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data pre-processing\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import python_speech_features as pss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from pysndfile import sndio\n",
        "from intervaltree import IntervalTree\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "WIN_LEN = 0.03\n",
        "WIN_SHIFT = 0.01\n",
        "\n",
        "\n",
        "def get_root_dir():\n",
        "    # TODO: adjust your path here\n",
        "    return Path('/') / 'content' / 'gdrive' / 'My Drive' / 'Dual Student'\n",
        "\n",
        "\n",
        "def load_audio(filepath):\n",
        "    \"\"\"\n",
        "    Loads the utterance samples from a file.\n",
        "\n",
        "    Source: lab3 of DT2119 Speech and Speaker Recognition at KTH, by prof. Giampiero Salvi (slightly modified)\n",
        "\n",
        "    :param filepath: path to the utterance file (.wav)\n",
        "    :return: (samples, sample rate), where samples is a numpy array of shape (n_samples,)\n",
        "    \"\"\"\n",
        "    snd_obj = sndio.read(filepath, dtype=np.int16)\n",
        "    samples = np.array(snd_obj[0])\n",
        "    sample_rate = snd_obj[1]\n",
        "    return samples, sample_rate\n",
        "\n",
        "\n",
        "def load_transcription(filepath):\n",
        "    \"\"\"\n",
        "    Loads the phonetic transcription of an utterance from a file.\n",
        "\n",
        "    :param filepath: path to the transcription file (.phn)\n",
        "    :return: list of tuples (begin_sample, end_sample, phone)\n",
        "    \"\"\"\n",
        "    with filepath.open() as f:\n",
        "        lines = f.read().split('\\n')\n",
        "    transcription = map(lambda line: line.split(' '), lines)\n",
        "    transcription = filter(lambda segment: len(segment) == 3, transcription)    # remove invalid lines\n",
        "    transcription = map(lambda segment: (int(segment[0]), int(segment[1]), segment[2]), transcription)\n",
        "    transcription = list(transcription)\n",
        "    return transcription\n",
        "\n",
        "\n",
        "def get_number_of_frames(n_samples, sample_rate, win_len, win_shift):\n",
        "    \"\"\"\n",
        "    Returns the number of frames for which the window is fully contained.\n",
        "\n",
        "    :param n_samples: number of samples\n",
        "    :param sample_rate: sampling rate\n",
        "    :param win_len: window length (in seconds)\n",
        "    :param win_shift: window shift (in seconds)\n",
        "    :return: number of frames\n",
        "    \"\"\"\n",
        "    win_len = round(win_len * sample_rate)\n",
        "    win_shift = round(win_shift * sample_rate)\n",
        "    return 1 + int((n_samples - win_len) / win_shift)\n",
        "\n",
        "\n",
        "def extract_features(samples, sample_rate, win_len, win_shift, win_fun=np.hamming):\n",
        "    \"\"\"\n",
        "    Computes 13 MFCC + delta + delta-delta features for an utterance.\n",
        "\n",
        "    :param samples: samples of the utterance, numpy array of shape (n_samples,)\n",
        "    :param sample_rate: sampling rate\n",
        "    :param win_len: window length (in seconds)\n",
        "    :param win_shift: window shift (in seconds)\n",
        "    :param win_fun: window function\n",
        "    :return: numpy array of shape (n_frames, n_features), where n_features=39\n",
        "    \"\"\"\n",
        "    mfcc = pss.mfcc(samples, sample_rate, winlen=win_len, winstep=win_shift, winfunc=win_fun)\n",
        "    delta = pss.delta(mfcc, 3)\n",
        "    delta_delta = pss.delta(delta, 3)\n",
        "    return np.concatenate((mfcc, delta, delta_delta), axis=1)\n",
        "\n",
        "\n",
        "def extract_labels(transcription, sample_rate, n_frames, win_len, win_shift):\n",
        "    \"\"\"\n",
        "    Extracts the phone labels from a phone transcription. The mid-point is used to solve ambiguities (frames with more\n",
        "    than one label).\n",
        "\n",
        "    :param transcription: phone transcription, list of tuples (begin_sample, end_sample, label)\n",
        "    :param sample_rate: sampling rate\n",
        "    :param n_frames: number of frames of the utterance\n",
        "    :param win_len: window length (in seconds)\n",
        "    :param win_shift: window shift (in seconds)\n",
        "    :return: list of length n_frames\n",
        "    \"\"\"\n",
        "    # fill interval tree\n",
        "    segments = IntervalTree()\n",
        "    for segment in transcription:\n",
        "        begin_sample = segment[0]\n",
        "        end_sample = segment[1]\n",
        "        label = segment[2]\n",
        "        assert len(segments[begin_sample:end_sample]) == 0    # no overlaps\n",
        "        segments[begin_sample:end_sample] = label\n",
        "\n",
        "    # seconds -> samples\n",
        "    win_len = round(win_len * sample_rate)\n",
        "    win_shift = round(win_shift * sample_rate)\n",
        "\n",
        "    # find labels of middle samples\n",
        "    labels = []\n",
        "    mid_sample = transcription[0][0] + int(win_len/2)\n",
        "    for i in range(n_frames):\n",
        "        labels.append(segments[mid_sample].pop().data)\n",
        "        mid_sample += win_shift\n",
        "    return labels\n",
        "\n",
        "\n",
        "def stack_acoustic_context(features, n):\n",
        "    \"\"\"\n",
        "    For each feature vector (frame), stack feature vectors on the left and on the right to get an acoustic context\n",
        "    (dynamic features).\n",
        "\n",
        "    :param features: original features, numpy array of shape (n_frames, n_features)\n",
        "    :param n: how many features on the left and on the right to stack (acoustic context or dynamic features)\n",
        "    :return: features with acoustic context, numpy array of shape (n_frames, context*n_features)\n",
        "    \"\"\"\n",
        "    if n < 0 or n > features.shape[0]:\n",
        "        raise ValueError('Invalid context size')\n",
        "    if n == 0:\n",
        "        return features\n",
        "    length = features.shape[0]\n",
        "    idx_list = list(range(length))\n",
        "    idx_list = idx_list[1:1+n][::-1] + idx_list + idx_list[-1-n:-1][::-1]\n",
        "    features = [features[idx_list[i:i+1+2*n]].reshape(-1) for i in range(length)]\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "def normalize(train_set, test_set, mode='full'):\n",
        "    \"\"\"\n",
        "    Normalizes the dataset according to the specified mode.\n",
        "\n",
        "    :param train_set: list of utterances, each utterance is a dictionary containing utterance info useful for\n",
        "        normalization, feature vectors, and phone labels.\n",
        "    :param test_set: list of utterances, each utterance is a dictionary containing utterance info useful for\n",
        "        normalization, feature vectors, and phone labels.\n",
        "    :param mode: normalization mode. Support for: 'full', 'speaker', 'utterance'.\n",
        "    :return: (train_set, test_set), normalized\n",
        "    \"\"\"\n",
        "    if mode == 'full':\n",
        "        # fit scaler\n",
        "        x_train = np.concatenate([utterance['features'] for utterance in train_set])\n",
        "        ss = StandardScaler()\n",
        "        ss.fit(x_train)\n",
        "\n",
        "        # normalize\n",
        "        for utterance in train_set:\n",
        "            utterance['features'] = ss.transform(utterance['features'])\n",
        "        for utterance in test_set:\n",
        "            utterance['features'] = ss.transform(utterance['features'])\n",
        "\n",
        "    elif mode == 'speaker':\n",
        "        # TODO\n",
        "        raise NotImplementedError('Normalization mode ' + mode + ' not yet supported')\n",
        "    elif mode == 'utterance':\n",
        "        # TODO\n",
        "        raise NotImplementedError('Normalization mode ' + mode + ' not yet supported')\n",
        "    else:\n",
        "        raise ValueError('Invalid normalization mode')\n",
        "\n",
        "    return train_set, test_set\n",
        "\n",
        "\n",
        "def path_to_info(path):\n",
        "    \"\"\"\n",
        "    Extracts the information about an utterance starting from its path.\n",
        "\n",
        "    Path format: .../<USAGE>/<DIALECT>/<SEX><SPEAKER_ID>/<TEXT_TYPE><SENTENCE_NUMBER>.<FILE_TYPE>\n",
        "    Example: .../train/dr1/mwar0/sx415.wav\n",
        "\n",
        "    See timit/readme.doc for an explanation of each field.\n",
        "\n",
        "    :param path: path the utterance file\n",
        "    :return: dictionary with utterance information\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'file_type': path.suffix,\n",
        "        'text_type': path.stem[:2],\n",
        "        'sentence_number': int(path.stem[2:]),\n",
        "        'sex': path.parts[-2][0],\n",
        "        'speaker_id': path.parts[-2][1:],\n",
        "        'dialect': path.parts[-3],\n",
        "        'usage': path.parts[-4]\n",
        "    }\n",
        "\n",
        "\n",
        "def get_core_test_speakers():\n",
        "    \"\"\"\n",
        "    Returns a dictionary (dialect -> list of speaker_id) for the core test set.\n",
        "\n",
        "    :return: dictionary (dialect -> list of speaker_id)\n",
        "    \"\"\"\n",
        "    filepath = get_root_dir() / 'data' / 'timit_core_test_set.json'\n",
        "    with filepath.open() as json_file:\n",
        "        return json.load(json_file)\n",
        "\n",
        "\n",
        "def get_phone_mapping():\n",
        "    \"\"\"\n",
        "    Generates:\n",
        "    - dictionary (origin phone -> train label), to load targets for the model from transcriptions. Different phones can\n",
        "        be mapped to the same label, as a subset of phones is used for training (48 phones).\n",
        "    - dictionary (train label -> test label), to evaluate the model on a subset of the training phones (39 phones).\n",
        "\n",
        "    The training and test phone subsets are chosen according to standard recipes for TIMIT.\n",
        "\n",
        "    :return: tuple (phone_labels, evaluation_mapping), containing the described dictionaries.\n",
        "    \"\"\"\n",
        "    # read file\n",
        "    filepath = get_root_dir() / 'data' / 'timit_phones_60-48-39.map'\n",
        "    with filepath.open() as csv_file:\n",
        "        data_frame = pd.read_csv(csv_file, sep='\\t')\n",
        "    data_frame = data_frame.dropna()\n",
        "\n",
        "    # load phone mappings\n",
        "    origin_to_train_phone = {op: tp for op, tp in zip(data_frame['origin'], data_frame['train'])}\n",
        "    origin_to_test_phone = {op: tp for op, tp in zip(data_frame['origin'], data_frame['test'])}\n",
        "\n",
        "    # generate labels (sorting in order to be sure that multiple calls generate always the same dictionaries)\n",
        "    train_labels = {phone: label for label, phone in enumerate(sorted(data_frame['train'].unique()))}\n",
        "    test_labels = {phone: label for label, phone in enumerate(sorted(data_frame['test'].unique()))}\n",
        "\n",
        "    # get phone labels (origin phone -> train label, to generate targets from transcriptions)\n",
        "    origin_to_train_label = {}\n",
        "    for origin_phone in data_frame['origin']:\n",
        "        train_phone = origin_to_train_phone[origin_phone]\n",
        "        origin_to_train_label[origin_phone] = train_labels[train_phone]\n",
        "\n",
        "    # get evaluation mapping (train label -> test label, to evaluate the model using a subset of phones)\n",
        "    train_label_to_test_label = {}\n",
        "    for origin_phone in data_frame['origin']:\n",
        "        test_phone = origin_to_test_phone[origin_phone]\n",
        "        train_label = origin_to_train_label[origin_phone]\n",
        "        train_label_to_test_label[train_label] = test_labels[test_phone]\n",
        "\n",
        "    return origin_to_train_label, train_label_to_test_label\n",
        "\n",
        "\n",
        "def _preprocess_data(dataset_path, core_test=False):\n",
        "    # get phone labels\n",
        "    phone_labels, _ = get_phone_mapping()\n",
        "\n",
        "    # get speakers in core test\n",
        "    core_test_speakers = None   # we need them only if core_test=True, we initialize to None to avoid a warning\n",
        "    if core_test:\n",
        "        core_test_speakers = get_core_test_speakers()\n",
        "\n",
        "    # prepare dataset\n",
        "    dataset = []\n",
        "    for filepath in dataset_path.glob('**/*.wav'):\n",
        "        info = path_to_info(filepath)\n",
        "\n",
        "        # check sentence and speaker\n",
        "        if info['text_type'] == 'sa':\n",
        "            continue\n",
        "        if core_test and not info['speaker_id'] in core_test_speakers[info['dialect']]:\n",
        "            continue\n",
        "\n",
        "        # load audio and transcription\n",
        "        print('Processing ', filepath, '...', sep='', end=' ')\n",
        "        samples, sample_rate = load_audio(filepath)\n",
        "        filepath = filepath.with_suffix('.phn')\n",
        "        transcription = load_transcription(filepath)\n",
        "\n",
        "        # drop leading and trailing samples not in the transcription\n",
        "        samples = samples[transcription[0][0]:transcription[-1][1]]\n",
        "\n",
        "        # extract features and labels\n",
        "        features = extract_features(samples, sample_rate, WIN_LEN, WIN_SHIFT)\n",
        "        n_frames = get_number_of_frames(samples.shape[0], sample_rate, WIN_LEN, WIN_SHIFT)\n",
        "        assert features.shape[0] - n_frames <= 1\n",
        "        features[:n_frames]     # the last frame may have the window not fully inside, we drop it\n",
        "        labels = extract_labels(transcription, sample_rate, n_frames, WIN_LEN, WIN_SHIFT)\n",
        "\n",
        "        # drop frames with ignored phones as target (glottal stop /q/)\n",
        "        labels = np.array([(phone_labels[label] if label in phone_labels else -1) for label in labels])\n",
        "        valid_idx = np.where(labels != -1)[0]\n",
        "        features = features[valid_idx]\n",
        "        labels = labels[valid_idx]\n",
        "        print('done')\n",
        "\n",
        "        # add to dataset\n",
        "        dataset.append({\n",
        "            'dialect': info['dialect'],\n",
        "            'sex': info['sex'],\n",
        "            'speaker_id': info['speaker_id'],\n",
        "            'features': features,\n",
        "            'labels': labels\n",
        "        })\n",
        "\n",
        "    return np.array(dataset)\n",
        "\n",
        "\n",
        "def load_data(dataset_path, core_test=True, force_preprocess=False):\n",
        "    \"\"\"\n",
        "    Returns training and test set containing features (13 MFCC + delta + delta-delta) and labels (phones encoded as\n",
        "    integers).\n",
        "\n",
        "    The split in training and test sets is the recommended one (see timit/readme.doc and timit/doc/testset.doc).\n",
        "\n",
        "    :param dataset_path: path to the dataset. Since the TIMIT dataset is protected by copyright, it is not distributed\n",
        "        with the package.\n",
        "    :param core_test: whether to use the core test set (see timit/doc/testset.doc) instead of the complete test set\n",
        "    :param force_preprocess: force to pre-process again, even if saved data can be loaded\n",
        "    :return: dictionary {'train': train_set, 'test': test_set}, where train_set and test_set are numpy arrays of\n",
        "        utterances. Each utterance is a dictionary containing utterance info useful for normalization, feature vectors,\n",
        "        and phone labels.\n",
        "    \"\"\"\n",
        "    dataset_path = Path(dataset_path)\n",
        "    if not dataset_path.is_dir():\n",
        "        raise ValueError('Invalid dataset path')\n",
        "\n",
        "    # training set\n",
        "    filepath = get_root_dir() / 'data' / 'timit_train.npz'\n",
        "    if filepath.is_file() and not force_preprocess:\n",
        "        print('Loading training set...', end=' ')\n",
        "        train_set = np.load(filepath, allow_pickle=True)['train_set']\n",
        "        print('done')\n",
        "    else:\n",
        "        print('Preparing training set...')\n",
        "        train_set = _preprocess_data(dataset_path / 'train')\n",
        "        np.savez(filepath, train_set=train_set)\n",
        "\n",
        "    # test set\n",
        "    filepath = get_root_dir() / 'data' / ('timit_' + ('core_' if core_test else '') + 'test.npz')\n",
        "    if filepath.is_file() and not force_preprocess:\n",
        "        print('Loading test set...', end=' ')\n",
        "        test_set = np.load(filepath, allow_pickle=True)['test_set']\n",
        "        print('done')\n",
        "    else:\n",
        "        print('Preparing test set...')\n",
        "        test_set = _preprocess_data(dataset_path / 'test', core_test)\n",
        "        np.savez(filepath, test_set=test_set)\n",
        "\n",
        "    return train_set, test_set\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPAmuTjgv8Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75514026-ff27-482e-8c4d-f5e887716fd2"
      },
      "source": [
        "#@title Data input pipeline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# set this according to your path\n",
        "DATASET_PATH = '/content/gdrive/My Drive/Dual Student/data/timit'\n",
        "BUFFER_SIZE = 1024\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def _get_tf_dataset(dataset, padding_values, shuffle=False):\n",
        "    features = [utterance['features'] for utterance in dataset]\n",
        "    labels = [utterance['labels'] for utterance in dataset]\n",
        "    n_features = features[0].shape[1]\n",
        "\n",
        "    x_dataset = tf.data.Dataset.from_generator(lambda: features, output_types=tf.float64)\n",
        "    y_dataset = tf.data.Dataset.from_generator(lambda: labels, output_types=tf.int32, output_shapes=(None,))\n",
        "    dataset = tf.data.Dataset.zip((x_dataset, y_dataset))\n",
        "    dataset = dataset.shuffle(buffer_size=BUFFER_SIZE)      # before padding, less memory used!\n",
        "    dataset = dataset.padded_batch(batch_size=BATCH_SIZE, padding_values=padding_values,\n",
        "                                   padded_shapes=((None, n_features), (None,)))\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_set, test_set = load_data(get_root_dir() / 'data' / 'timit')\n",
        "train_set, test_set = normalize(train_set, test_set)\n",
        "\n",
        "# define input pipeline\n",
        "# TODO: choose padding values not present in the dataset\n",
        "padding_values = (tf.constant(-50, dtype=tf.float64), tf.constant(50, dtype=tf.int32))\n",
        "train_ds = _get_tf_dataset(train_set, padding_values, shuffle=True)\n",
        "test_ds = _get_tf_dataset(train_set, padding_values)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training set... done\n",
            "Loading test set... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oLzOSGMFosD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Model\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import newaxis\n",
        "\n",
        "\n",
        "class DualStudent():\n",
        "\n",
        "    def __init__(self, nr_of_units=768, nr_of_layers=6, nr_of_classes=61, student_version=\"Mono_directional\", show_summary=True, epsilon=0.016395, lambda_1=1, lambda_2=10000):\n",
        "        self.nr_of_units=nr_of_units\n",
        "        self.nr_of_layers=nr_of_layers\n",
        "        self.nr_of_classes=nr_of_classes\n",
        "        self.student_version=student_version\n",
        "        self.x=None\n",
        "        self.y=None\n",
        "        self.lambda_1=lambda_1\n",
        "        self.lambda_2=lambda_2\n",
        "        self.epsilon=epsilon\n",
        "        self.cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "        self.mse = tf.keras.losses.MeanSquaredError()\n",
        "        self.show_summary=show_summary\n",
        "        self.get_data()\n",
        "        if self.student_version==\"Mono_directional\":\n",
        "            self.student1=self.get_model(\"student1\")\n",
        "            self.student2=self.get_model(\"student2\")\n",
        "\n",
        "        elif self.student_version==\"Imbalanced\":\n",
        "            self.student1=self.get_model(\"student1\")\n",
        "            self.student2=self.get_model(\"student2\", lstm_version=\"Bi_directional\")\n",
        "\n",
        "        else:\n",
        "            self.student1=self.get_model(\"student1\" , lstm_version=\"Bi_directional\" )\n",
        "            self.student2=self.get_model(\"student2\", lstm_version=\"Bi_directional\" )\n",
        "        \n",
        "        self.models={\"student1\":self.student1,\"student2\":self.student2}\n",
        "\n",
        "    def get_data(self):\n",
        "        with open('/content/gdrive/My Drive/train_xspeech.npy', 'rb') as f:\n",
        "            train_x = np.load(f)\n",
        "            self.y = np.load(f)\n",
        "\n",
        "        shape_=np.shape(train_x)\n",
        "        x_train=train_x[:,newaxis,:]\n",
        "        tf.reshape(x_train,(shape_[0],1, shape_[1]) )\n",
        "        self.x = x_train \n",
        "\n",
        "    def get_model(self, name_=\"\", lstm_version=\"Mono_directional\"):\n",
        "        inputs = tf.keras.Input(shape=np.shape(self.x)[1:])\n",
        "\n",
        "        if lstm_version==\"Bi_directional\":\n",
        "            x=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True))(inputs) \n",
        "            for i in range(self.nr_of_layers-3):\n",
        "                x=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True))(x)  \n",
        "            x=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=False))(x)  \n",
        "            outputs=tf.keras.layers.Dense(units=self.nr_of_classes, activation=\"softmax\")(x)\n",
        "\n",
        "        else:\n",
        "            x=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True)(inputs) \n",
        "            for i in range(self.nr_of_layers-3):\n",
        "                x=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True)(x)  \n",
        "            x=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=False)(x)  \n",
        "            outputs=tf.keras.layers.Dense(units=self.nr_of_classes, activation=\"softmax\")(x)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs, name=lstm_version+\"_\"+name_)\n",
        "        if self.show_summary:  \n",
        "            model.summary()\n",
        "            print(\"\\n\\n\")\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, name='SGD')\n",
        "        model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "    \n",
        "    def train(self, x=None, y=None, nr_epochs=100, batch_size=100, unlabeled_x=None):\n",
        "        if x==None and y==None:\n",
        "            x=self.x\n",
        "            y=self.y\n",
        "\n",
        "        self.epochs=nr_epochs\n",
        "        losses={}\n",
        "        stable_samples={}\n",
        "        for epoch in range(1,self.epochs+1):\n",
        "            #model=\"student1\"\n",
        "            #Y_pred=self.models[model].predict(x)\n",
        "            #print(\"accuracy\",tf.reduce_mean(tf.keras.metrics.categorical_accuracy(y, Y_pred)))\n",
        "            for i in range(int(np.ceil(np.size(x,0)/batch_size))):\n",
        "                x_batch=x[i*batch_size:(i+1)*batch_size]\n",
        "                y_true=y[i*batch_size:(i+1)*batch_size]\n",
        "                B_1=x_batch + np.random.random(np.shape(x_batch))*0.1\n",
        "                B_2=x_batch + np.random.random(np.shape(x_batch))*0.1\n",
        "\n",
        "                #change this when we get real data\n",
        "                unlabeled_x=x[0:100]\n",
        "                noisy_augmentation = unlabeled_x + np.random.random(np.shape(unlabeled_x))\n",
        "\n",
        "                with tf.GradientTape(persistent=True) as tape:\n",
        "                    for model in self.models:\n",
        "                    \n",
        "                        # Calculate L_cls on labeled samples\n",
        "                        y_pred=self.models[model](x_batch)\n",
        "                        loss_cls =  self.cce(y_true, y_pred)\n",
        "\n",
        "                        # Calculate L_con by Eq. 1 between B1 and B2\n",
        "                        y_B_1=self.models[model](B_1)\n",
        "                        y_B_2=self.models[model](B_2)\n",
        "                        loss_con= self.lambda_1 * self.mse(y_B_1, y_B_2)\n",
        "                        losses[model+\"_loss\"] = loss_cls + self.lambda_1 * loss_con\n",
        "                        \n",
        "                        # Determine whether x is stable by Eq. 3\n",
        "                        U_pred=self.models[model](unlabeled_x)\n",
        "                        noisy_pred=self.models[model](noisy_augmentation)\n",
        "                        \n",
        "                        P_i=tf.argmax(U_pred, axis=1)\n",
        "                        P_j=tf.argmax(noisy_pred, axis=1)   \n",
        "                        M_i=tf.math.reduce_max(U_pred, axis=1) \n",
        "                        M_j=tf.math.reduce_max(noisy_pred, axis=1)  \n",
        "                        M_i_j=tf.where(tf.where(M_i>self.epsilon,1,0)+tf.where(M_j>self.epsilon,1,0)>0,1,0)\n",
        "                        \n",
        "                        stable_samples[model]=tf.where(P_i==P_j,1,0)*M_i_j \n",
        "                        stable_samples[model+\"_pred\"]=U_pred \n",
        "                        stable_samples[model+\"_noise\"]=noisy_pred\n",
        "\n",
        "\n",
        "                    # R_1, R_2, R_i, R_j and R_12 does not mean the same thing as in the paper\n",
        "                    R_1=tf.where(stable_samples[\"student1\"]-stable_samples[\"student2\"]>0,True,False)                \n",
        "                    R_2=tf.where(stable_samples[\"student2\"]-stable_samples[\"student1\"]>0,True,False)\n",
        "                    R_12=tf.where(stable_samples[\"student1\"]+stable_samples[\"student2\"]==2,True,False)\n",
        "                    \n",
        "                    # where both R_1 and R_2 are equal to one (R_12) measure prediction consistancy with Euclidean distance\n",
        "                    epsilon_i=tf.math.reduce_euclidean_norm(stable_samples[\"student1_pred\"][R_12]-stable_samples[\"student1_noise\"][R_12], axis=1)\n",
        "                    epsilon_j=tf.math.reduce_euclidean_norm(stable_samples[\"student2_pred\"][R_12]-stable_samples[\"student2_noise\"][R_12], axis=1)\n",
        "                    R_i=epsilon_i>epsilon_j\n",
        "                    R_j=epsilon_i<=epsilon_j\n",
        "\n",
        "                    # loss_sta for student 1\n",
        "                    sample1_update1=tf.concat([stable_samples[\"student1_pred\"][R_2], stable_samples[\"student1_pred\"][R_12][R_i]],axis=0)\n",
        "                    sample2_update1=tf.concat([stable_samples[\"student2_pred\"][R_2], stable_samples[\"student2_pred\"][R_12][R_i]],axis=0)\n",
        "                    loss_sta=self.mse(sample1_update1, sample2_update1)\n",
        "                    losses[\"student1_loss\"] = losses[\"student1_loss\"] + self.lambda_2 * loss_sta\n",
        "\n",
        "                    # loss_sta for student 2\n",
        "                    sample1_update2=tf.concat([stable_samples[\"student1_pred\"][R_1], stable_samples[\"student1_pred\"][R_12][R_j]],axis=0)\n",
        "                    sample2_update2=tf.concat([stable_samples[\"student2_pred\"][R_1], stable_samples[\"student2_pred\"][R_12][R_j]],axis=0)\n",
        "                    loss_sta=self.mse(sample1_update2, sample2_update2)\n",
        "                    losses[\"student2_loss\"] = losses[\"student2_loss\"] + self.lambda_2 * loss_sta\n",
        "\n",
        "                # update the model parameters \n",
        "                for model in self.models:\n",
        "                    trainable_vars = self.models[model].trainable_variables\n",
        "                    gradients = tape.gradient(losses[model+\"_loss\"], trainable_vars)\n",
        "                    self.models[model].optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "                del tape"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHHUGyiKA5DT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "6e128e55-d382-429d-8e01-55c21fc638d6"
      },
      "source": [
        "#@title Training\n",
        "\n",
        "# train model\n",
        "models={}\n",
        "for version_ in [\"Mono_directional\", \"Imbalanced\", \"Bi_directional\"]:\n",
        "    models[version_]=DualStudent(student_version=version_)\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "models[\"Mono_directional\"].train(nr_epochs=5)\n",
        "# TODO: with TIMIT dataset...\n",
        "\n",
        "# evaluate model\n",
        "# TODO"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c90677241d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mversion_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Mono_directional\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Imbalanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Bi_directional\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mversion_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDualStudent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-59fab0d92417>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nr_of_units, nr_of_layers, nr_of_classes, student_version, show_summary, epsilon, lambda_1, lambda_2)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudent_version\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"Mono_directional\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudent1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"student1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-59fab0d92417>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/train_xspeech.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/train_xspeech.npy'"
          ]
        }
      ]
    }
  ]
}