{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DT2119_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VVu1WXfq2Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKMXTmDiTqiB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from numpy import newaxis\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "with open('/content/gdrive/My Drive/train_xspeech.npy', 'rb') as f:\n",
        "            train_x = np.load(f)\n",
        "            y = np.load(f)\n",
        "\n",
        "shape_=np.shape(train_x)\n",
        "x_train=train_x[:,newaxis,:]\n",
        "tf.reshape(x_train,(shape_[0],1, shape_[1]) )\n",
        "x = x_train "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxdrqhW2H7R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DualStudent(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(DualStudent, self).__init__()\n",
        "        self.nr_of_units=768\n",
        "        self.nr_of_layers=5\n",
        "        self.nr_of_classes=61\n",
        "        self.student_1={}\n",
        "        self.student_2={}\n",
        "        for student in [self.student_1]:#, self.student_2]:\n",
        "            for i in range(self.nr_of_layers-1):\n",
        "                student[\"layer\"+str(i+1)]=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True)  \n",
        "            student[\"layer\"+str(5)]=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=False)\n",
        "            student[\"layer\"+str(6)]=tf.keras.layers.Dense(units=self.nr_of_classes)\n",
        "\n",
        "\n",
        "    def call(self,  inputs):\n",
        "        x1=self.student_1[\"layer\"+str(1)](inputs)\n",
        "        #x2=self.student_2[\"layer\"+str(1)](inputs)\n",
        "\n",
        "        for i in range(self.nr_of_layers):\n",
        "            x1=self.student_1[\"layer\"+str(i+2)](x1)\n",
        "            #x2=self.student_2[\"layer\"+str(1+2)](x2)\n",
        "        return x1 #,x2\n",
        "\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "model = DualStudent()\n",
        "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x, y, epochs=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3zLCQm_vfNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Functional API\n",
        "\n",
        "class DualStudent():\n",
        "\n",
        "    def __init__(self, nr_of_units=768, nr_of_layers=6, nr_of_classes=61, student_version=\"Mono_directional\",show_summary=True):\n",
        "        self.nr_of_units=nr_of_units\n",
        "        self.nr_of_layers=nr_of_layers\n",
        "        self.nr_of_classes=nr_of_classes\n",
        "        self.student_version=student_version\n",
        "        self.x=None\n",
        "        self.y=None\n",
        "        self.get_data()\n",
        "        self.show_summary=show_summary\n",
        "        if self.student_version==\"Mono_directional\":\n",
        "            self.student1=self.get_model(\"student1\")\n",
        "            self.student2=self.get_model(\"student2\")\n",
        "\n",
        "        elif self.student_version==\"Imbalanced\":\n",
        "            self.student1=self.get_model(\"student1\")\n",
        "            self.student2=self.get_model(\"student2\", lstm_version=\"Bi_directional\")\n",
        "\n",
        "        else:\n",
        "            self.student1=self.get_model(\"student1\" , lstm_version=\"Bi_directional\" )\n",
        "            self.student2=self.get_model(\"student2\", lstm_version=\"Bi_directional\" )\n",
        "        \n",
        "\n",
        "\n",
        "    def get_data(self):\n",
        "        with open('/content/gdrive/My Drive/train_xspeech.npy', 'rb') as f:\n",
        "            train_x = np.load(f)\n",
        "            self.y = np.load(f)\n",
        "\n",
        "        shape_=np.shape(train_x)\n",
        "        x_train=train_x[:,newaxis,:]\n",
        "        tf.reshape(x_train,(shape_[0],1, shape_[1]) )\n",
        "        self.x = x_train \n",
        "\n",
        "    def get_model(self, name_=\"\", lstm_version=\"Mono_directional\"):\n",
        "        inputs = tf.keras.Input(shape=np.shape(self.x)[1:])\n",
        "\n",
        "        if lstm_version==\"Bi_directional\":\n",
        "            x=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True))(inputs) \n",
        "            for i in range(self.nr_of_layers-3):\n",
        "                x=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True))(x)  \n",
        "            x=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=False))(x)  \n",
        "            outputs=tf.keras.layers.Dense(units=self.nr_of_classes)(x)\n",
        "\n",
        "        else:\n",
        "            x=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True)(inputs) \n",
        "            for i in range(self.nr_of_layers-3):\n",
        "                x=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=True)(x)  \n",
        "            x=tf.keras.layers.LSTM(units=self.nr_of_units, return_sequences=False)(x)  \n",
        "            outputs=tf.keras.layers.Dense(units=self.nr_of_classes)(x)\n",
        "\n",
        "        # In case someone rather have it as one model instead of 2.\n",
        "        # change the name from x to x1 and then write the same code for x2\n",
        "        # and then the following line:\n",
        "        # model = tf.keras.Model(inputs=inputs, outputs=[x1,x2])\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs, name=lstm_version+\"_\"+name_)\n",
        "        if self.show_summary:  \n",
        "            model.summary()\n",
        "            print(\"\\n\\n\")\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, name='SGD')\n",
        "        model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "    \n",
        "    def train(self, x=None, y=None, nr_epochs=100):\n",
        "        if x==None and y==None:\n",
        "            x=self.x\n",
        "            y=self.y\n",
        "\n",
        "        self.student1.fit(x, y, epochs=nr_epochs, batch_size=100)\n",
        "        self.student2.fit(x, y, epochs=nr_epochs)\n",
        "\n",
        "models={}\n",
        "for version_ in [\"Mono_directional\", \"Imbalanced\", \"Bi_directional\"]:\n",
        "    models[version_]=DualStudent(student_version=version_)\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "models[\"Mono_directional\"].train(nr_epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}